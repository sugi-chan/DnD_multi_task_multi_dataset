{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# License: BSD\n",
    "# Author: Sasank Chilamkurthy\n",
    "\n",
    "from __future__ import print_function, division\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.optim import lr_scheduler\n",
    "import numpy as np\n",
    "import torchvision\n",
    "from torchvision import datasets, models, transforms\n",
    "import matplotlib.pyplot as plt\n",
    "import time\n",
    "import os\n",
    "import copy\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from PIL import Image\n",
    "from random import randrange\n",
    "import torch.nn.functional as F\n",
    "\n",
    "\n",
    "plt.ion()   # interactive mode"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "\n",
    "dat_race = pd.read_csv('dnd_race.csv')\n",
    "dat_class = pd.read_csv('dnd_class.csv')\n",
    "\n",
    "dat_race['image_path'] = dat_race['label']+'/'+dat_race['image_number']\n",
    "dat_class['image_path'] = dat_class['label']+'/'+dat_class['image_number']\n",
    "\n",
    "dat_race = dat_race.rename(index=str, columns={\"label\": \"race\"})\n",
    "dat_class = dat_class.rename(index=str, columns={\"label\": \"class\"})\n",
    "dat_class.head(1)\n",
    "\n",
    "\n",
    "X_race = dat_race['image_path']\n",
    "X_class = dat_class['image_path']\n",
    "\n",
    "y_race = pd.get_dummies(dat_race['race'])\n",
    "y_class = pd.get_dummies(dat_class['class'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "rogue      148\n",
       "paladin    147\n",
       "wizard     119\n",
       "Name: class, dtype: int64"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dat_class['class'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.357487922705314"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "148/dat_class.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "elf           188\n",
       "gnome         122\n",
       "dragonborn    120\n",
       "Name: race, dtype: int64"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dat_race.race.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.4372093023255814"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "188/dat_race.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_race_train, X_race_test, y_race_train, y_race_test = train_test_split(X_race, y_race, test_size=0.20, random_state=42)\n",
    "X_class_train, X_class_test, y_class_train, y_class_test = train_test_split(X_class, y_class, test_size=0.20, random_state=42)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_race_train = X_race_train.values.tolist()\n",
    "X_race_test = X_race_test.values.tolist()\n",
    "\n",
    "\n",
    "X_class_train = X_class_train.values.tolist()\n",
    "X_class_test = X_class_test.values.tolist()\n",
    "\n",
    "race_shape = y_race_train.shape[1]\n",
    "class_shape = y_class_train.shape[1]\n",
    "\n",
    "\n",
    "y_race_train = y_race_train.values.tolist()\n",
    "y_race_test = y_race_test.values.tolist()\n",
    "\n",
    "y_class_train = y_class_train.values.tolist()\n",
    "y_class_test = y_class_test.values.tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "344"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(y_race_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "331"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(y_class_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "#for i in dataset_style:\n",
    "#    print(i,dat[i].sum(),dat[i].sum()/dat.shape[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "#for i in dataset_rest:\n",
    "#    print(i,dat[i].sum(),dat[i].sum()/dat.shape[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import random\n",
    "flip = random.randint(0, 1)\n",
    "flip"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "class fgo_dataset(Dataset):\n",
    "    def __init__(self,king_of_lists, transform=None):\n",
    "        \"\"\"\n",
    "        gender_img, style_img, gender_pred,style_pred \n",
    "        \n",
    "        Args:\n",
    "            csv_file (string): Path to the csv file with annotations.\n",
    "            root_dir (string): Directory with all the images.\n",
    "            transform (callable, optional): Optional transform to be applied\n",
    "                on a sample.\n",
    "        \"\"\"\n",
    "        self.king_of_lists = king_of_lists\n",
    "        self.transform = transform\n",
    "        \n",
    "    def __getitem__(self,index):\n",
    "        \n",
    "        #random_index = randrange(len(self.king_of_lists[index]))\n",
    "        \n",
    "        img1 = Image.open('images/'+self.king_of_lists[0][index])\n",
    "        img1 = img1.convert('RGB')\n",
    "        \n",
    "        #img2 = Image.open('images/'+self.king_of_lists[1][index])\n",
    "        #img2 = img2.convert('RGB')\n",
    "        \n",
    "        \n",
    "        gender = self.king_of_lists[1][index] # gender\n",
    "        #color = self.king_of_lists[3][index] # region\n",
    "        \n",
    "        if self.transform is not None:\n",
    "            img1 = self.transform(img1)\n",
    "\n",
    "        list_of_labels = [torch.from_numpy(np.array(gender))]\n",
    "       \n",
    "        return img1, list_of_labels[0]\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.king_of_lists[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda:0\n"
     ]
    }
   ],
   "source": [
    "batch_size = 8\n",
    "# Data augmentation and normalization for training\n",
    "# Just normalization for validation\n",
    "data_transforms = {\n",
    "    'train': transforms.Compose([\n",
    "        transforms.Resize((256,256)),\n",
    "        transforms.RandomResizedCrop(224),\n",
    "        transforms.RandomHorizontalFlip(),\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])\n",
    "    ]),\n",
    "    'val': transforms.Compose([\n",
    "        transforms.Resize((224,224)),\n",
    "        #transforms.CenterCrop(224),\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])\n",
    "    ]),\n",
    "}\n",
    "\n",
    "train_lists = [X_race_train, y_race_train]\n",
    "test_lists = [X_race_test, y_race_test ]\n",
    "\n",
    "training_dataset = fgo_dataset(king_of_lists = train_lists,\n",
    "                               transform = data_transforms['train'] )\n",
    "\n",
    "test_dataset = fgo_dataset(king_of_lists = test_lists,\n",
    "                           transform = data_transforms['val'] )\n",
    "\n",
    "dataloaders_dict = {'train': torch.utils.data.DataLoader(training_dataset, batch_size=batch_size, shuffle=True, num_workers=0),\n",
    "                   'val':torch.utils.data.DataLoader(test_dataset, batch_size=batch_size, shuffle=True, num_workers=0)\n",
    "                   }\n",
    "dataset_sizes = {'train':len(train_lists[0]),\n",
    "                'val':len(test_lists[0])}\n",
    "\n",
    "\n",
    "train_class_lists = [X_class_train, y_class_train]\n",
    "test_class_lists = [X_class_test, y_class_test ]\n",
    "\n",
    "training_style_dataset = fgo_dataset(king_of_lists = train_class_lists,\n",
    "                               transform = data_transforms['train'] )\n",
    "\n",
    "test_style_dataset = fgo_dataset(king_of_lists = test_class_lists,\n",
    "                           transform = data_transforms['val'] )\n",
    "\n",
    "dataloaders_style_dict = {'train': torch.utils.data.DataLoader(training_style_dataset, batch_size=batch_size,drop_last =True, shuffle=True, num_workers=0),\n",
    "                   'val':torch.utils.data.DataLoader(test_style_dataset, batch_size=batch_size,drop_last =True, shuffle=True, num_workers=0)\n",
    "                   }\n",
    "dataloaders_style_sizes = {'train':len(train_lists[0]),\n",
    "                'val':len(test_lists[0])}\n",
    "\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "41 10\n"
     ]
    }
   ],
   "source": [
    "print(len(dataloaders_style_dict['train']),len(dataloaders_style_dict['val']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "43 11\n"
     ]
    }
   ],
   "source": [
    "print(len(dataloaders_dict['train']),len(dataloaders_dict['val']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ResNet(\n",
      "  (conv1): Conv2d(3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False)\n",
      "  (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (relu): ReLU(inplace)\n",
      "  (maxpool): MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)\n",
      "  (layer1): Sequential(\n",
      "    (0): Bottleneck(\n",
      "      (conv1): Conv2d(64, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace)\n",
      "      (downsample): Sequential(\n",
      "        (0): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "    )\n",
      "    (1): Bottleneck(\n",
      "      (conv1): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace)\n",
      "    )\n",
      "    (2): Bottleneck(\n",
      "      (conv1): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace)\n",
      "    )\n",
      "  )\n",
      "  (layer2): Sequential(\n",
      "    (0): Bottleneck(\n",
      "      (conv1): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace)\n",
      "      (downsample): Sequential(\n",
      "        (0): Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
      "        (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "    )\n",
      "    (1): Bottleneck(\n",
      "      (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace)\n",
      "    )\n",
      "    (2): Bottleneck(\n",
      "      (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace)\n",
      "    )\n",
      "    (3): Bottleneck(\n",
      "      (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace)\n",
      "    )\n",
      "  )\n",
      "  (layer3): Sequential(\n",
      "    (0): Bottleneck(\n",
      "      (conv1): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace)\n",
      "      (downsample): Sequential(\n",
      "        (0): Conv2d(512, 1024, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
      "        (1): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "    )\n",
      "    (1): Bottleneck(\n",
      "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace)\n",
      "    )\n",
      "    (2): Bottleneck(\n",
      "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace)\n",
      "    )\n",
      "    (3): Bottleneck(\n",
      "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace)\n",
      "    )\n",
      "    (4): Bottleneck(\n",
      "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace)\n",
      "    )\n",
      "    (5): Bottleneck(\n",
      "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace)\n",
      "    )\n",
      "  )\n",
      "  (layer4): Sequential(\n",
      "    (0): Bottleneck(\n",
      "      (conv1): Conv2d(1024, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace)\n",
      "      (downsample): Sequential(\n",
      "        (0): Conv2d(1024, 2048, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
      "        (1): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "    )\n",
      "    (1): Bottleneck(\n",
      "      (conv1): Conv2d(2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace)\n",
      "    )\n",
      "    (2): Bottleneck(\n",
      "      (conv1): Conv2d(2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace)\n",
      "    )\n",
      "  )\n",
      "  (avgpool): AdaptiveAvgPool2d(output_size=(1, 1))\n",
      "  (fc): Linear(in_features=2048, out_features=1000, bias=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ")\n",
      "multi_output_model(\n",
      "  (resnet_model): ResNet(\n",
      "    (conv1): Conv2d(3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False)\n",
      "    (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (relu): ReLU(inplace)\n",
      "    (maxpool): MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)\n",
      "    (layer1): Sequential(\n",
      "      (0): Bottleneck(\n",
      "        (conv1): Conv2d(64, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "        (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu): ReLU(inplace)\n",
      "        (downsample): Sequential(\n",
      "          (0): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "          (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        )\n",
      "      )\n",
      "      (1): Bottleneck(\n",
      "        (conv1): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "        (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu): ReLU(inplace)\n",
      "      )\n",
      "      (2): Bottleneck(\n",
      "        (conv1): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "        (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu): ReLU(inplace)\n",
      "      )\n",
      "    )\n",
      "    (layer2): Sequential(\n",
      "      (0): Bottleneck(\n",
      "        (conv1): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "        (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu): ReLU(inplace)\n",
      "        (downsample): Sequential(\n",
      "          (0): Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
      "          (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        )\n",
      "      )\n",
      "      (1): Bottleneck(\n",
      "        (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "        (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu): ReLU(inplace)\n",
      "      )\n",
      "      (2): Bottleneck(\n",
      "        (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "        (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu): ReLU(inplace)\n",
      "      )\n",
      "      (3): Bottleneck(\n",
      "        (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "        (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu): ReLU(inplace)\n",
      "      )\n",
      "    )\n",
      "    (layer3): Sequential(\n",
      "      (0): Bottleneck(\n",
      "        (conv1): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu): ReLU(inplace)\n",
      "        (downsample): Sequential(\n",
      "          (0): Conv2d(512, 1024, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
      "          (1): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        )\n",
      "      )\n",
      "      (1): Bottleneck(\n",
      "        (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu): ReLU(inplace)\n",
      "      )\n",
      "      (2): Bottleneck(\n",
      "        (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu): ReLU(inplace)\n",
      "      )\n",
      "      (3): Bottleneck(\n",
      "        (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu): ReLU(inplace)\n",
      "      )\n",
      "      (4): Bottleneck(\n",
      "        (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu): ReLU(inplace)\n",
      "      )\n",
      "      (5): Bottleneck(\n",
      "        (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu): ReLU(inplace)\n",
      "      )\n",
      "    )\n",
      "    (layer4): Sequential(\n",
      "      (0): Bottleneck(\n",
      "        (conv1): Conv2d(1024, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "        (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu): ReLU(inplace)\n",
      "        (downsample): Sequential(\n",
      "          (0): Conv2d(1024, 2048, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
      "          (1): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        )\n",
      "      )\n",
      "      (1): Bottleneck(\n",
      "        (conv1): Conv2d(2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "        (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu): ReLU(inplace)\n",
      "      )\n",
      "      (2): Bottleneck(\n",
      "        (conv1): Conv2d(2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "        (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu): ReLU(inplace)\n",
      "      )\n",
      "    )\n",
      "    (avgpool): AdaptiveAvgPool2d(output_size=(1, 1))\n",
      "    (fc): Linear(in_features=2048, out_features=512, bias=True)\n",
      "  )\n",
      "  (x1): Linear(in_features=512, out_features=512, bias=True)\n",
      "  (x1a): Linear(in_features=512, out_features=512, bias=True)\n",
      "  (x2): Linear(in_features=512, out_features=256, bias=True)\n",
      "  (x2a): Linear(in_features=256, out_features=256, bias=True)\n",
      "  (x3): Linear(in_features=256, out_features=128, bias=True)\n",
      "  (x3a): Linear(in_features=128, out_features=128, bias=True)\n",
      "  (y1o): Linear(in_features=128, out_features=3, bias=True)\n",
      "  (y2o): Linear(in_features=128, out_features=3, bias=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ")\n",
      "<generator object Module.parameters at 0x0000024585B3E840>\n"
     ]
    }
   ],
   "source": [
    "model_ft = models.resnet50(pretrained=True)\n",
    "#for param in model_ft.parameters():\n",
    "#    param.requires_grad = False\n",
    "print(model_ft)\n",
    "#num_ftrs = model_ft.classifier[6].in_features\n",
    "num_ftrs = model_ft.fc.in_features\n",
    "model_ft.fc = nn.Linear(num_ftrs, 512)\n",
    "\n",
    "#race_shape = y_race_train.shape[1]\n",
    "#class_shape = y_class_train.shape[1]\n",
    "class multi_output_model(torch.nn.Module):\n",
    "    def __init__(self, model_core):\n",
    "        super(multi_output_model, self).__init__()\n",
    "        \n",
    "        self.resnet_model = model_core\n",
    "        \n",
    "        self.x1 =  nn.Linear(512,512)\n",
    "        nn.init.xavier_normal_(self.x1.weight)\n",
    "        self.x1a =  nn.Linear(512,512)\n",
    "        nn.init.xavier_normal_(self.x1a.weight)\n",
    "        \n",
    "        self.x2 =  nn.Linear(512,256)\n",
    "        nn.init.xavier_normal_(self.x2.weight)\n",
    "        self.x2a =  nn.Linear(256,256)\n",
    "        nn.init.xavier_normal_(self.x2a.weight)\n",
    "        \n",
    "        self.x3 =  nn.Linear(256,128)\n",
    "        nn.init.xavier_normal_(self.x3.weight)\n",
    "        self.x3a =  nn.Linear(128,128)\n",
    "        nn.init.xavier_normal_(self.x3a.weight)\n",
    "        #comp head 1\n",
    "        \n",
    "        \n",
    "        #heads\n",
    "        self.y1o = nn.Linear(128,race_shape)\n",
    "        nn.init.xavier_normal_(self.y1o.weight)#\n",
    "        self.y2o = nn.Linear(128,class_shape)\n",
    "        nn.init.xavier_normal_(self.y2o.weight)\n",
    "        \n",
    "    def forward(self, x):\n",
    "       \n",
    "        x1 = self.resnet_model(x)\n",
    "        #x1 =  F.relu(self.x1(x1))\n",
    "        #x1 =  F.relu(self.x2(x1))\n",
    "        \n",
    "        x1 =  F.relu(self.x1(x1))\n",
    "        x1 =  F.relu(self.x1a(x1))\n",
    "        x1 =  F.relu(self.x2(x1))\n",
    "        x1 =  F.relu(self.x2a(x1))\n",
    "        \n",
    "        x1 =  F.relu(self.x3(x1))\n",
    "        x1 =  F.relu(self.x3a(x1))\n",
    "        \n",
    "        \n",
    "        #x = F.relu(self.x2(x))\n",
    "        #x1 = F.relu(self.x3(x))\n",
    "        \n",
    "        # heads\n",
    "        y1o = F.softmax(self.y1o(x1),dim=1)\n",
    "        y2o = F.softmax(self.y2o(x1),dim=1)\n",
    "        #y2o = torch.sigmoid(self.y2o(x1)) #should be sigmoid\n",
    "\n",
    "\n",
    "        return y1o, y2o\n",
    "model_1 = multi_output_model(model_ft)\n",
    "model_1 = model_1.to(device)\n",
    "model_1.load_state_dict(torch.load('./models/masked_resnet34.pth'))\n",
    "\n",
    "print(model_1)\n",
    "print(model_1.parameters())    \n",
    "criterion = [nn.CrossEntropyLoss(),nn.CrossEntropyLoss()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([[1.1028e-02, 9.6551e-01, 2.3460e-02],\n",
       "         [7.6354e-04, 9.9167e-01, 7.5649e-03],\n",
       "         [7.2412e-01, 2.3155e-02, 2.5273e-01],\n",
       "         [9.5255e-02, 5.8714e-01, 3.1760e-01],\n",
       "         [2.4761e-03, 9.4278e-01, 5.4747e-02],\n",
       "         [5.7927e-01, 2.2151e-01, 1.9923e-01],\n",
       "         [1.6586e-01, 4.0949e-01, 4.2465e-01],\n",
       "         [9.9525e-02, 4.6703e-02, 8.5377e-01]], device='cuda:0',\n",
       "        grad_fn=<SoftmaxBackward>), tensor([[0.0174, 0.0246, 0.9579],\n",
       "         [0.0042, 0.1050, 0.8908],\n",
       "         [0.9657, 0.0195, 0.0148],\n",
       "         [0.3038, 0.2287, 0.4675],\n",
       "         [0.0053, 0.9885, 0.0062],\n",
       "         [0.7765, 0.1442, 0.0793],\n",
       "         [0.4382, 0.5468, 0.0150],\n",
       "         [0.2207, 0.7228, 0.0566]], device='cuda:0', grad_fn=<SoftmaxBackward>))"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "it = iter(dataloaders_style_dict['val'])\n",
    "gender_input ,gender = next(it)\n",
    "x1,x2 = model_1(gender_input.to(device) )\n",
    "x1,x2\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.autograd import Variable\n",
    "def train_model(model, criterion, optimizer, scheduler, num_epochs=25):\n",
    "    since = time.time()\n",
    "    print('starting')\n",
    "    best_model_wts = copy.deepcopy(model.state_dict())\n",
    "    best_loss = 100\n",
    "\n",
    "    for epoch in range(num_epochs):\n",
    "        print('Epoch {}/{}'.format(epoch, num_epochs - 1))\n",
    "        print('-' * 10)\n",
    "\n",
    "        # Each epoch has a training and validation phase\n",
    "        for phase in ['train', 'val']:\n",
    "            if phase == 'train':\n",
    "                scheduler.step()\n",
    "                model.train()  # Set model to training mode\n",
    "            else:\n",
    "                model.eval()   # Set model to evaluate mode\n",
    "\n",
    "            running_loss = 0.0\n",
    "            running_loss0= 0.0\n",
    "            running_loss1= 0.0\n",
    "            \n",
    "            #color_corrects= []\n",
    "            #total_colors = []\n",
    "            gender_corrects = 0.0\n",
    "            color_corrects= 0.0\n",
    "            \n",
    "            num_class_preds = 0\n",
    "            num_gender_preds = 0 \n",
    "            # Iterate over data.\n",
    "            gender_iterator = iter(dataloaders_dict[phase])\n",
    "\n",
    "            style_iterator = iter(dataloaders_style_dict[phase])\n",
    "            \n",
    "            #number_of_batches = len(dataloaders_style_dict[phase]) + len(dataloaders_dict[phase])\n",
    "            for i in range(len(dataloaders_style_dict[phase])):\n",
    "                #dataloaders_dict , dataloaders_style_dict\n",
    "                \n",
    "                ### gender\n",
    "                inputs,labels_ = next(gender_iterator)\n",
    "                \n",
    "                inputs = inputs.to(device) \n",
    "                labels_ = labels_.to(device)\n",
    "                \n",
    "                outputs = model(inputs)\n",
    "                preds_ = outputs[0]\n",
    "                \n",
    "                loss_gender = criterion[0](preds_, torch.max(labels_.float(), 1)[1]).to(device)\n",
    "                running_loss0 += loss_gender.item() * inputs.size(0)\n",
    "                gender_corrects += torch.sum(torch.max(preds_, 1)[1] == torch.max(labels_, 1)[1])\n",
    "                num_gender_preds += inputs.size(0)\n",
    "                #loss = loss_gender\n",
    "                #running_loss += loss.item() * inputs.size(0)\n",
    "                \n",
    "                #optimizer.zero_grad()\n",
    "                \n",
    "                #if phase == 'train':\n",
    "                        \n",
    "                #        loss.backward(retain_graph=True)\n",
    "                #        optimizer.step()\n",
    "                        \n",
    "                #####################################################################################\n",
    "                ### style\n",
    "                inputs,labels_ = next(style_iterator)\n",
    "                inputs = inputs.to(device) \n",
    "                labels_ = labels_.to(device)\n",
    "                \n",
    "                outputs = model(inputs)\n",
    "                preds_ = outputs[1]\n",
    "\n",
    "                loss_style = criterion[1](preds_, torch.max(labels_.float(), 1)[1]).to(device)\n",
    "                running_loss1 += loss_style.item() * inputs.size(0)\n",
    "                color_corrects += torch.sum(torch.max(preds_, 1)[1] == torch.max(labels_, 1)[1])\n",
    "                num_class_preds += inputs.size(0)\n",
    "                #loss = loss_style\n",
    "                \n",
    "                \n",
    "                optimizer.zero_grad()\n",
    "                \n",
    "                loss = loss_style + loss_gender\n",
    "                running_loss += loss.item() * inputs.size(0)*2\n",
    "                if phase == 'train':\n",
    "                        \n",
    "                    loss.backward()\n",
    "                    optimizer.step()\n",
    "            \n",
    "                \n",
    "            epoch_loss = running_loss / (num_class_preds +num_gender_preds)\n",
    "            epoch_loss0 = running_loss0 / (num_gender_preds)\n",
    "            epoch_loss1 = running_loss1 / (num_class_preds)\n",
    "\n",
    "            \n",
    "            color_acc = color_corrects.double()/num_class_preds\n",
    "            gender_corrects = gender_corrects.double() / num_gender_preds\n",
    "            \n",
    "            print('{} total loss: {:.4f} dnd_race loss: {:.4f} dnd_class loss: {:.4f}'.format(phase,epoch_loss,epoch_loss0,\n",
    "                                                                                                          epoch_loss1))\n",
    "            print('{} race_acc: {:.4f} '\n",
    "                  'class_acc: {:.4f}'.format(\n",
    "                phase, gender_corrects,color_acc))\n",
    "\n",
    "            if phase == 'val' and epoch_loss < best_loss:\n",
    "                print('saving with loss of {}'.format(epoch_loss),\n",
    "                      'improved over previous {}'.format(best_loss))\n",
    "                best_loss = epoch_loss\n",
    "                best_model_wts = copy.deepcopy(model.state_dict())\n",
    "                torch.save(best_model_wts, './models/masked_resnet34.pth')\n",
    "\n",
    "\n",
    "        print()\n",
    "\n",
    "    time_elapsed = time.time() - since\n",
    "    print('Training complete in {:.0f}m {:.0f}s'.format(\n",
    "        time_elapsed // 60, time_elapsed % 60))\n",
    "    print('Best val Acc: {:4f}'.format(float(best_loss)))\n",
    "\n",
    "    # load best model weights\n",
    "    model.load_state_dict(best_model_wts)\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "lrmain = .000001\n",
    "lrlast = .0001\n",
    "optim1 = optim.Adam(\n",
    "    [\n",
    "        {\"params\":model_1.resnet_model.parameters(),\"lr\": lrmain},\n",
    "        {\"params\":model_1.x1.parameters(), \"lr\": lrlast},\n",
    "        {\"params\":model_1.x1a.parameters(), \"lr\": lrlast},\n",
    "        {\"params\":model_1.x2.parameters(), \"lr\": lrlast},\n",
    "        {\"params\":model_1.x2a.parameters(), \"lr\": lrlast},\n",
    "       {\"params\":model_1.x3.parameters(), \"lr\": lrlast},\n",
    "       {\"params\":model_1.x3a.parameters(), \"lr\": lrlast},\n",
    "       {\"params\":model_1.y1o.parameters(), \"lr\": lrlast},\n",
    "         {\"params\":model_1.y2o.parameters(), \"lr\": lrlast},\n",
    "       \n",
    "       \n",
    "   ])\n",
    "\n",
    "#optim1 = optim.Adam(model_1.parameters(), lr=0.01)#,momentum=.9)\n",
    "# Observe that all parameters are being optimized\n",
    "optimizer_ft = optim1\n",
    "\n",
    "# Decay LR by a factor of 0.1 every 7 epochs\n",
    "exp_lr_scheduler = lr_scheduler.StepLR(optimizer_ft, step_size=6, gamma=0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "starting\n",
      "Epoch 0/29\n",
      "----------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\Users\\micha\\Anaconda3\\envs\\tensorflow_env\\lib\\site-packages\\PIL\\TiffImagePlugin.py:785: UserWarning: Corrupt EXIF data.  Expecting to read 4 bytes but only got 0. \n",
      "  warnings.warn(str(msg))\n",
      "D:\\Users\\micha\\Anaconda3\\envs\\tensorflow_env\\lib\\site-packages\\PIL\\Image.py:965: UserWarning: Palette images with Transparency   expressed in bytes should be converted to RGBA images\n",
      "  ' expressed in bytes should be converted ' +\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train total loss: 1.7396 dnd_race loss: 0.8834 dnd_class loss: 0.8562\n",
      "train race_acc: 0.6585 class_acc: 0.6860\n",
      "val total loss: 1.8055 dnd_race loss: 0.9258 dnd_class loss: 0.8797\n",
      "val race_acc: 0.6125 class_acc: 0.6625\n",
      "saving with loss of 1.8055377364158631 improved over previous 100\n",
      "\n",
      "Epoch 1/29\n",
      "----------\n",
      "train total loss: 1.7609 dnd_race loss: 0.9038 dnd_class loss: 0.8571\n",
      "train race_acc: 0.6494 class_acc: 0.6707\n",
      "val total loss: 1.7175 dnd_race loss: 0.8677 dnd_class loss: 0.8498\n",
      "val race_acc: 0.6500 class_acc: 0.6750\n",
      "saving with loss of 1.7175435781478883 improved over previous 1.8055377364158631\n",
      "\n",
      "Epoch 2/29\n",
      "----------\n",
      "train total loss: 1.7490 dnd_race loss: 0.9037 dnd_class loss: 0.8453\n",
      "train race_acc: 0.6311 class_acc: 0.7104\n",
      "val total loss: 1.9169 dnd_race loss: 0.9560 dnd_class loss: 0.9609\n",
      "val race_acc: 0.5375 class_acc: 0.5875\n",
      "\n",
      "Epoch 3/29\n",
      "----------\n",
      "train total loss: 1.7063 dnd_race loss: 0.8624 dnd_class loss: 0.8439\n",
      "train race_acc: 0.6951 class_acc: 0.6982\n",
      "val total loss: 1.7390 dnd_race loss: 0.8747 dnd_class loss: 0.8643\n",
      "val race_acc: 0.6750 class_acc: 0.6625\n",
      "\n",
      "Epoch 4/29\n",
      "----------\n",
      "train total loss: 1.6677 dnd_race loss: 0.8511 dnd_class loss: 0.8166\n",
      "train race_acc: 0.7012 class_acc: 0.7256\n",
      "val total loss: 1.7565 dnd_race loss: 0.8879 dnd_class loss: 0.8686\n",
      "val race_acc: 0.6375 class_acc: 0.6625\n",
      "\n",
      "Epoch 5/29\n",
      "----------\n",
      "train total loss: 1.6382 dnd_race loss: 0.8293 dnd_class loss: 0.8089\n",
      "train race_acc: 0.7409 class_acc: 0.7500\n",
      "val total loss: 1.7408 dnd_race loss: 0.8799 dnd_class loss: 0.8608\n",
      "val race_acc: 0.6000 class_acc: 0.6625\n",
      "\n",
      "Epoch 6/29\n",
      "----------\n",
      "train total loss: 1.6663 dnd_race loss: 0.8369 dnd_class loss: 0.8294\n",
      "train race_acc: 0.7134 class_acc: 0.7195\n",
      "val total loss: 1.7407 dnd_race loss: 0.8831 dnd_class loss: 0.8576\n",
      "val race_acc: 0.6500 class_acc: 0.6750\n",
      "\n",
      "Epoch 7/29\n",
      "----------\n",
      "train total loss: 1.6748 dnd_race loss: 0.8428 dnd_class loss: 0.8320\n",
      "train race_acc: 0.7104 class_acc: 0.7134\n",
      "val total loss: 1.7216 dnd_race loss: 0.8773 dnd_class loss: 0.8443\n",
      "val race_acc: 0.6375 class_acc: 0.7000\n",
      "\n",
      "Epoch 8/29\n",
      "----------\n",
      "train total loss: 1.6484 dnd_race loss: 0.8494 dnd_class loss: 0.7990\n",
      "train race_acc: 0.7043 class_acc: 0.7439\n",
      "val total loss: 1.7392 dnd_race loss: 0.8784 dnd_class loss: 0.8608\n",
      "val race_acc: 0.6375 class_acc: 0.6875\n",
      "\n",
      "Epoch 9/29\n",
      "----------\n",
      "train total loss: 1.6343 dnd_race loss: 0.8342 dnd_class loss: 0.8002\n",
      "train race_acc: 0.7195 class_acc: 0.7470\n",
      "val total loss: 1.7242 dnd_race loss: 0.8810 dnd_class loss: 0.8432\n",
      "val race_acc: 0.6750 class_acc: 0.7000\n",
      "\n",
      "Epoch 10/29\n",
      "----------\n",
      "train total loss: 1.6887 dnd_race loss: 0.8505 dnd_class loss: 0.8382\n",
      "train race_acc: 0.7012 class_acc: 0.7104\n",
      "val total loss: 1.7017 dnd_race loss: 0.8687 dnd_class loss: 0.8330\n",
      "val race_acc: 0.6875 class_acc: 0.7000\n",
      "saving with loss of 1.7017206788063048 improved over previous 1.7175435781478883\n",
      "\n",
      "Epoch 11/29\n",
      "----------\n",
      "train total loss: 1.6092 dnd_race loss: 0.8249 dnd_class loss: 0.7842\n",
      "train race_acc: 0.7287 class_acc: 0.7774\n",
      "val total loss: 1.6816 dnd_race loss: 0.8400 dnd_class loss: 0.8415\n",
      "val race_acc: 0.7000 class_acc: 0.7125\n",
      "saving with loss of 1.6815574049949646 improved over previous 1.7017206788063048\n",
      "\n",
      "Epoch 12/29\n",
      "----------\n",
      "train total loss: 1.6549 dnd_race loss: 0.8433 dnd_class loss: 0.8117\n",
      "train race_acc: 0.7195 class_acc: 0.7287\n",
      "val total loss: 1.6970 dnd_race loss: 0.8661 dnd_class loss: 0.8309\n",
      "val race_acc: 0.6750 class_acc: 0.7250\n",
      "\n",
      "Epoch 13/29\n",
      "----------\n",
      "train total loss: 1.6415 dnd_race loss: 0.8086 dnd_class loss: 0.8329\n",
      "train race_acc: 0.7530 class_acc: 0.7073\n",
      "val total loss: 1.7016 dnd_race loss: 0.8522 dnd_class loss: 0.8495\n",
      "val race_acc: 0.7000 class_acc: 0.6875\n",
      "\n",
      "Epoch 14/29\n",
      "----------\n",
      "train total loss: 1.6522 dnd_race loss: 0.8230 dnd_class loss: 0.8292\n",
      "train race_acc: 0.7348 class_acc: 0.7134\n",
      "val total loss: 1.7548 dnd_race loss: 0.8777 dnd_class loss: 0.8771\n",
      "val race_acc: 0.6750 class_acc: 0.6625\n",
      "\n",
      "Epoch 15/29\n",
      "----------\n",
      "train total loss: 1.6696 dnd_race loss: 0.8594 dnd_class loss: 0.8102\n",
      "train race_acc: 0.6921 class_acc: 0.7439\n",
      "val total loss: 1.7145 dnd_race loss: 0.8546 dnd_class loss: 0.8599\n",
      "val race_acc: 0.6750 class_acc: 0.6750\n",
      "\n",
      "Epoch 16/29\n",
      "----------\n",
      "train total loss: 1.6127 dnd_race loss: 0.8186 dnd_class loss: 0.7941\n",
      "train race_acc: 0.7378 class_acc: 0.7530\n",
      "val total loss: 1.7234 dnd_race loss: 0.8628 dnd_class loss: 0.8606\n",
      "val race_acc: 0.6750 class_acc: 0.6750\n",
      "\n",
      "Epoch 17/29\n",
      "----------\n",
      "train total loss: 1.6242 dnd_race loss: 0.8326 dnd_class loss: 0.7916\n",
      "train race_acc: 0.7226 class_acc: 0.7622\n",
      "val total loss: 1.7252 dnd_race loss: 0.9035 dnd_class loss: 0.8216\n",
      "val race_acc: 0.6250 class_acc: 0.7250\n",
      "\n",
      "Epoch 18/29\n",
      "----------\n",
      "train total loss: 1.6424 dnd_race loss: 0.8142 dnd_class loss: 0.8282\n",
      "train race_acc: 0.7439 class_acc: 0.7134\n",
      "val total loss: 1.7572 dnd_race loss: 0.8826 dnd_class loss: 0.8747\n",
      "val race_acc: 0.6500 class_acc: 0.6500\n",
      "\n",
      "Epoch 19/29\n",
      "----------\n",
      "train total loss: 1.7152 dnd_race loss: 0.8661 dnd_class loss: 0.8491\n",
      "train race_acc: 0.6829 class_acc: 0.6829\n",
      "val total loss: 1.7435 dnd_race loss: 0.8716 dnd_class loss: 0.8719\n",
      "val race_acc: 0.6500 class_acc: 0.6500\n",
      "\n",
      "Epoch 20/29\n",
      "----------\n",
      "train total loss: 1.6362 dnd_race loss: 0.8176 dnd_class loss: 0.8187\n",
      "train race_acc: 0.7439 class_acc: 0.7226\n",
      "val total loss: 1.7370 dnd_race loss: 0.8738 dnd_class loss: 0.8632\n",
      "val race_acc: 0.6500 class_acc: 0.6875\n",
      "\n",
      "Epoch 21/29\n",
      "----------\n",
      "train total loss: 1.6483 dnd_race loss: 0.8557 dnd_class loss: 0.7926\n",
      "train race_acc: 0.7012 class_acc: 0.7561\n",
      "val total loss: 1.7278 dnd_race loss: 0.8697 dnd_class loss: 0.8581\n",
      "val race_acc: 0.6625 class_acc: 0.6625\n",
      "\n",
      "Epoch 22/29\n",
      "----------\n",
      "train total loss: 1.6102 dnd_race loss: 0.8136 dnd_class loss: 0.7966\n",
      "train race_acc: 0.7409 class_acc: 0.7470\n",
      "val total loss: 1.7267 dnd_race loss: 0.8618 dnd_class loss: 0.8649\n",
      "val race_acc: 0.6875 class_acc: 0.6500\n",
      "\n",
      "Epoch 23/29\n",
      "----------\n",
      "train total loss: 1.5950 dnd_race loss: 0.8041 dnd_class loss: 0.7909\n",
      "train race_acc: 0.7591 class_acc: 0.7439\n",
      "val total loss: 1.7303 dnd_race loss: 0.8670 dnd_class loss: 0.8633\n",
      "val race_acc: 0.7000 class_acc: 0.6625\n",
      "\n",
      "Epoch 24/29\n",
      "----------\n",
      "train total loss: 1.6487 dnd_race loss: 0.8417 dnd_class loss: 0.8071\n",
      "train race_acc: 0.6829 class_acc: 0.7256\n",
      "val total loss: 1.8269 dnd_race loss: 0.9294 dnd_class loss: 0.8975\n",
      "val race_acc: 0.5875 class_acc: 0.6000\n",
      "\n",
      "Epoch 25/29\n",
      "----------\n",
      "train total loss: 1.6243 dnd_race loss: 0.8146 dnd_class loss: 0.8097\n",
      "train race_acc: 0.7500 class_acc: 0.7317\n",
      "val total loss: 1.7250 dnd_race loss: 0.8615 dnd_class loss: 0.8636\n",
      "val race_acc: 0.7000 class_acc: 0.6625\n",
      "\n",
      "Epoch 26/29\n",
      "----------\n",
      "train total loss: 1.6234 dnd_race loss: 0.8210 dnd_class loss: 0.8023\n",
      "train race_acc: 0.7378 class_acc: 0.7652\n",
      "val total loss: 1.6849 dnd_race loss: 0.8474 dnd_class loss: 0.8375\n",
      "val race_acc: 0.7000 class_acc: 0.7250\n",
      "\n",
      "Epoch 27/29\n",
      "----------\n",
      "train total loss: 1.6247 dnd_race loss: 0.8015 dnd_class loss: 0.8232\n",
      "train race_acc: 0.7561 class_acc: 0.7165\n",
      "val total loss: 1.7113 dnd_race loss: 0.8549 dnd_class loss: 0.8564\n",
      "val race_acc: 0.7000 class_acc: 0.6500\n",
      "\n",
      "Epoch 28/29\n",
      "----------\n",
      "train total loss: 1.6635 dnd_race loss: 0.8241 dnd_class loss: 0.8394\n",
      "train race_acc: 0.7317 class_acc: 0.6921\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-22-f837d3e08a99>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m model_ft1 = train_model(model_1, criterion, optimizer_ft, exp_lr_scheduler,\n\u001b[1;32m----> 2\u001b[1;33m                        num_epochs=30)\n\u001b[0m",
      "\u001b[1;32m<ipython-input-20-4b0a0555e4bd>\u001b[0m in \u001b[0;36mtrain_model\u001b[1;34m(model, criterion, optimizer, scheduler, num_epochs)\u001b[0m\n\u001b[0;32m     63\u001b[0m                 \u001b[1;31m#####################################################################################\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     64\u001b[0m                 \u001b[1;31m### style\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 65\u001b[1;33m                 \u001b[0minputs\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mlabels_\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnext\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mstyle_iterator\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     66\u001b[0m                 \u001b[0minputs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0minputs\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mto\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     67\u001b[0m                 \u001b[0mlabels_\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mlabels_\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mto\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\Users\\micha\\Anaconda3\\envs\\tensorflow_env\\lib\\site-packages\\torch\\utils\\data\\dataloader.py\u001b[0m in \u001b[0;36m__next__\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    558\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mnum_workers\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m:\u001b[0m  \u001b[1;31m# same-process loading\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    559\u001b[0m             \u001b[0mindices\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnext\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msample_iter\u001b[0m\u001b[1;33m)\u001b[0m  \u001b[1;31m# may raise StopIteration\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 560\u001b[1;33m             \u001b[0mbatch\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcollate_fn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mindices\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    561\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpin_memory\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    562\u001b[0m                 \u001b[0mbatch\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0m_utils\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpin_memory\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpin_memory_batch\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mbatch\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\Users\\micha\\Anaconda3\\envs\\tensorflow_env\\lib\\site-packages\\torch\\utils\\data\\dataloader.py\u001b[0m in \u001b[0;36m<listcomp>\u001b[1;34m(.0)\u001b[0m\n\u001b[0;32m    558\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mnum_workers\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m:\u001b[0m  \u001b[1;31m# same-process loading\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    559\u001b[0m             \u001b[0mindices\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnext\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msample_iter\u001b[0m\u001b[1;33m)\u001b[0m  \u001b[1;31m# may raise StopIteration\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 560\u001b[1;33m             \u001b[0mbatch\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcollate_fn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mindices\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    561\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpin_memory\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    562\u001b[0m                 \u001b[0mbatch\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0m_utils\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpin_memory\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpin_memory_batch\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mbatch\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-14-4c0100d4c964>\u001b[0m in \u001b[0;36m__getitem__\u001b[1;34m(self, index)\u001b[0m\n\u001b[0;32m     18\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     19\u001b[0m         \u001b[0mimg1\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mImage\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mopen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'images/'\u001b[0m\u001b[1;33m+\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mking_of_lists\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mindex\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 20\u001b[1;33m         \u001b[0mimg1\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mimg1\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mconvert\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'RGB'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     21\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     22\u001b[0m         \u001b[1;31m#img2 = Image.open('images/'+self.king_of_lists[1][index])\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\Users\\micha\\Anaconda3\\envs\\tensorflow_env\\lib\\site-packages\\PIL\\Image.py\u001b[0m in \u001b[0;36mconvert\u001b[1;34m(self, mode, matrix, dither, palette, colors)\u001b[0m\n\u001b[0;32m    910\u001b[0m         \"\"\"\n\u001b[0;32m    911\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 912\u001b[1;33m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mload\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    913\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    914\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0mmode\u001b[0m \u001b[1;32mand\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmode\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;34m\"P\"\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\Users\\micha\\Anaconda3\\envs\\tensorflow_env\\lib\\site-packages\\PIL\\ImageFile.py\u001b[0m in \u001b[0;36mload\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    240\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    241\u001b[0m                             \u001b[0mb\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mb\u001b[0m \u001b[1;33m+\u001b[0m \u001b[0ms\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 242\u001b[1;33m                             \u001b[0mn\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0merr_code\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mdecoder\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdecode\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mb\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    243\u001b[0m                             \u001b[1;32mif\u001b[0m \u001b[0mn\u001b[0m \u001b[1;33m<\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    244\u001b[0m                                 \u001b[1;32mbreak\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "model_ft1 = train_model(model_1, criterion, optimizer_ft, exp_lr_scheduler,\n",
    "                       num_epochs=30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "gender = ['gender_Female',\n",
    "       'gender_Male']\n",
    "\n",
    "for i in gender:\n",
    "    print(y_train[i].value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "237/(237+89)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Eval\n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "dd = .2\n",
    "model_ft = models.resnet50(pretrained=True)\n",
    "for param in model_ft.parameters():\n",
    "    param.requires_grad = False\n",
    "#print(model_ft)\n",
    "num_ftrs = model_ft.fc.in_features\n",
    "model_ft.fc = nn.Linear(num_ftrs, 512)\n",
    "\n",
    "model1 = multi_output_model(model_ft,dd)\n",
    "#print(model1)\n",
    "model1 = model1.to(device)\n",
    "model1.load_state_dict(torch.load('models/res502.pth'))\n",
    "model1.eval()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.autograd import Variable\n",
    "\n",
    "imsize = 224\n",
    "loader = transforms.Compose([transforms.Resize((imsize,imsize)),\n",
    "                             transforms.ToTensor(),\n",
    "                             transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])])\n",
    "\n",
    "def image_loader(image_name):\n",
    "    \"\"\"load image, returns cuda tensor\"\"\"\n",
    "    image = Image.open('test/'+image_name)\n",
    "    image = image.convert('RGB')\n",
    "    \n",
    "    image = loader(image).float()\n",
    "    print(image.shape)\n",
    "    image = Variable(image, requires_grad=False)\n",
    "    image = image.unsqueeze(0)  #this is for VGG, may not be needed for ResNet\n",
    "    return image.cuda()  #assumes that you're using GPU\n",
    "\n",
    "#saber4.png\n",
    "\n",
    "image = image_loader('jalter3.jpg')\n",
    "y_pred = model1(image)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "values, indices = torch.max(y_pred[1], -1)\n",
    "print(y_pred[1],values, indices)\n",
    "\n",
    "torch.topk(y_pred[1],1)[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "   \n",
    "gender = ['Female',\n",
    "       'Male']\n",
    "region = ['Asia', 'Egypt', 'Europe',\n",
    "       'Middle East']\n",
    "fighting_style = ['magic', 'melee',\n",
    "       'ranged']\n",
    "alignment = ['CE', 'CG', 'CN',\n",
    "       'LE', 'LG', 'LN', 'NE',\n",
    "       'NG', 'TN']\n",
    "colors = ['white', 'red',\n",
    "       'green', 'black', 'blue', 'purple', 'gold', 'silver']\n",
    "\n",
    "def extract_label(label_list, pred_array,top_n=1):\n",
    "    pred_max = torch.topk(pred_array,top_n)[1]\n",
    "    print(pred_max)\n",
    "    out_list = []\n",
    "    for i in pred_max[0]:\n",
    "        out_list.append(label_list[i])\n",
    "    return out_list\n",
    "\n",
    "print(extract_label(gender,y_pred[0]))\n",
    "print(extract_label(region,y_pred[1]))\n",
    "print(extract_label(fighting_style,y_pred[2]))\n",
    "print(extract_label(alignment,y_pred[3]))\n",
    "print(extract_label(colors,y_pred[4],3))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from os import listdir\n",
    "from matplotlib.pyplot import imshow\n",
    "\n",
    "%matplotlib inline\n",
    "#pil_im = Image.open('data/empire.jpg', 'r')\n",
    "\n",
    "test = listdir('test/')\n",
    "    \n",
    "for i in test:\n",
    "    \n",
    "\n",
    "    image = image_loader(i)\n",
    "    y_pred = model1(image)\n",
    "    print(i)\n",
    "    print('')\n",
    "    print('image: ', i )\n",
    "    print(extract_label(gender,y_pred[0]))\n",
    "    print(extract_label(region,y_pred[1]))\n",
    "    print(extract_label(fighting_style,y_pred[2]))\n",
    "    print(extract_label(alignment,y_pred[3]))\n",
    "    print(extract_label(colors,y_pred[4],3))\n",
    "    pil_im = Image.open('test/'+i)\n",
    "    \n",
    "    plt.imshow(np.asarray(pil_im))\n",
    "    plt.xticks([]), plt.yticks([])  # to hide tick values on X and Y axis\n",
    "    plt.show()\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
